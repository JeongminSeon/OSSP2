{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sp2uHkUYrItd","executionInfo":{"status":"ok","timestamp":1670653262002,"user_tz":-540,"elapsed":26674,"user":{"displayName":"Point Check","userId":"12583793856941705124"}},"outputId":"dc328877-24ad-4d56-90af-ff657b269db3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","AGENT_1 = 100\n","AGENT_2 = 200\n","ACT_MOVE_CNT = 4\n","ACT_MOVE_NORTH = 0\n","ACT_MOVE_WEST = 1\n","ACT_MOVE_SOUTH = 2\n","ACT_MOVE_EAST = 3\n","\n","\n","class QuoridorEnv():\n","\n","    def __init__(self, width=5, value_mode=0):\n","        if (width > 10 or width < 4 or width % 2 == 0):\n","            raise Exception(\n","                'QuoridorEnv 초기화 에러!\\nwidth 조건: width < 10 and width > 4 and width % 2 == 1')\n","        if (value_mode > 4 and value_mode < 0):\n","            raise Exception(\n","                'QuoridorEnv 초기화 에러!\\nvalue_mode 조건: value_mode >= 0 and value_mode < 5')\n","        self.width = width\n","        self.wall_map_width = width - 1\n","        self.wall_cnt = (width * width) // 8\n","        self.value_mode = value_mode\n","        self.agent1 = False\n","        self.agent2 = False\n","        self.last_played = AGENT_2\n","        self.state_changed = True\n","        self.agNumList = [AGENT_1, AGENT_2]\n","        # wall_map_width * wall_map_width * 2 형식의 3차원 배열\n","        # map: [2][wall_map_width][wall_map_width]이다.\n","        # [0][][]: 가로로 배치된 벽\n","        # [1][][]: 새로로 배치된 벽\n","        self.map = np.array([\n","            [[False] * self.wall_map_width for _ in range(self.wall_map_width)] for _ in range(2)])\n","        self.player_status = np.array([[width // 2, 0, self.wall_cnt],\n","                                       [width // 2, width - 1, self.wall_cnt]])\n","\n","        # legal 여부와 상관 없이 취할 수 있는 모든 action의 집합 (nwse이동) + (wall 배치 동작 개수)\n","        self.all_action = np.array(\n","            [True] * (4 + self.wall_map_width * self.wall_map_width * 2))\n","\n","    def register_agent(self):\n","        if not self.agent1:\n","            self.agent1 = True\n","            return AGENT_1\n","        elif not self.agent2:\n","            self.agent2 = True\n","            return AGENT_2\n","        else:\n","            raise Exception(\n","                '에이전트 등록 에러!\\n3개 이상의 에이전트 등록 시도.')\n","\n","    def reset(self, width=-1, value_mode=-1):\n","        if width == -1:\n","            width = self.width\n","        if value_mode == -1:\n","            value_mode = self.value_mode\n","        self.__init__(width=width, value_mode=value_mode)\n","        return self.get_state(300 - self.last_played)\n","\n","    def get_legal_action(self, state=\"\"):\n","        if (state == \"\"):\n","            state = (self.map, self.player_status)\n","        my_pos = (state[1][0][0], state[1][0][1])\n","        opp_pos = (state[1][1][0], state[1][1][1])\n","        width = self.width\n","        ret = self.all_action.copy()\n","\n","        # 이동 가능한지 여부 확인\n","        # N\n","        if (my_pos[1] >= width - 1):\n","            ret[ACT_MOVE_NORTH] = False\n","        elif ((my_pos[0] != 0 and state[0][0][my_pos[0] - 1][my_pos[1]]) or (my_pos[0] < width - 1 and state[0][0][my_pos[0]][my_pos[1]])):\n","            ret[ACT_MOVE_NORTH] = False\n","        # W\n","        if (my_pos[0] == 0):\n","            ret[ACT_MOVE_WEST] = False\n","        elif ((my_pos[1] != 0 and state[0][1][my_pos[0] - 1][my_pos[1] - 1]) or (my_pos[1] < width - 1 and state[0][1][my_pos[0] - 1][my_pos[1]])):\n","            ret[ACT_MOVE_WEST] = False\n","        # S\n","        if (my_pos[1] == 0):\n","            ret[ACT_MOVE_SOUTH] = False\n","        elif ((my_pos[0] != 0 and state[0][0][my_pos[0] - 1][my_pos[1] - 1]) or (my_pos[0] < width - 1 and state[0][0][my_pos[0]][my_pos[1] - 1])):\n","            ret[ACT_MOVE_SOUTH] = False\n","        # E\n","        if (my_pos[0] >= width - 1):\n","            ret[ACT_MOVE_EAST] = False\n","        elif ((my_pos[1] != 0 and state[0][1][my_pos[0]][my_pos[1] - 1]) or (my_pos[1] < width - 1 and state[0][1][my_pos[0]][my_pos[1]])):\n","            ret[ACT_MOVE_EAST] = False\n","\n","        # 벽설치 가능 여부\n","        # 가로 벽\n","        if state[1][0][2] > 0:\n","            for x in range(width - 1):\n","                for y in range(width - 1):\n","                    # 가로 벽\n","                    if ((x != 0 and state[0][0][x-1][y]) or state[0][0][x][y] or state[0][1][x][y] or (x < (width - 2) and state[0][0][x+1][y])):\n","                        ret[ACT_MOVE_CNT + y * (width - 1) + x] = False\n","                    # 새로 벽\n","                    if ((y != 0 and state[0][1][x][y-1]) or state[0][1][x][y] or state[0][0][x][y] or (y < (width - 2) and state[0][1][x][y+1])):\n","                        ret[ACT_MOVE_CNT + (width - 1) *\n","                            (width - 1) + y * (width - 1) + x] = False\n","\n","            # 경로 방해여부 검사\n","            for x in range(width - 1):\n","                for y in range(width - 1):\n","                    if (ret[ACT_MOVE_CNT + y * (width - 1) + x]):\n","                        tmp_map = state[0].copy()\n","                        tmp_map[0][x][y] = True\n","                        if (self.ask_how_far((tmp_map, state[1])) == -1 or self.ask_how_far_opp((tmp_map, state[1])) == -1):\n","                            ret[ACT_MOVE_CNT + y * (width - 1) + x] = False\n","                    if (ret[ACT_MOVE_CNT + (width - 1) * (width - 1) + y * (width - 1) + x]):\n","                        tmp_map = state[0].copy()\n","                        tmp_map[1][x][y] = True\n","                        if (self.ask_how_far((tmp_map, state[1])) == -1 or self.ask_how_far_opp((tmp_map, state[1])) == -1):\n","                            ret[ACT_MOVE_CNT + (width - 1) * (width - 1) +\n","                                y * (width - 1) + x] = False\n","        else:\n","            for x in range(width - 1):\n","                for y in range(width - 1):\n","                    ret[ACT_MOVE_CNT + y * (width - 1) + x] = False\n","                    ret[ACT_MOVE_CNT + (width - 1) * (width - 1) +\n","                        y * (width - 1) + x] = False\n","        res = []\n","        for i, j in enumerate(ret):\n","            if j:\n","                res.append(i)\n","        return res\n","\n","    def render(self, agent_num):\n","        if (agent_num != AGENT_1 and agent_num != AGENT_2):\n","            raise Exception(\n","                'QuoridorEnv- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","        state = None\n","        if (agent_num != AGENT_1):\n","            state = self.get_flipped_state()\n","        else:\n","            state = (self.map, self.player_status)\n","        output = []\n","        output.append(\"\\n\\n=========NORTH=========\\n\")\n","        # Map 출력\n","        for i in reversed(range(self.width)):\n","\n","           # 가로 wall 을 배치하는 파트\n","            if (i < self.wall_map_width):\n","                output.append(\"  \")\n","                for j in range(self.wall_map_width):\n","                    if (j != 0 and state[0][0][j - 1][i]):\n","                        output.append(\"===\")\n","                    elif (state[0][0][j][i]):\n","                        output.append(\"====\")\n","                        continue\n","                    else:\n","                        output.append(\"   \")\n","                    if (state[0][1][j][i]):\n","                        output.append(\"|\")\n","                    else:\n","                        output.append(\" \")\n","                if (state[0][0][self.wall_map_width - 1][i]):\n","                    output.append(\"===\")\n","                if (not state[0][0][self.wall_map_width - 1][i]):\n","                    output.append(\"   \")\n","                output.append(\"\\n\")\n","\n","            output.append(str(i))\n","            output.append(\" \")\n","            for j in range(self.width):\n","\n","                # 플레이어 배치하는 파트\n","                # p1 의 위치는 빨간색으로 표기\n","                if (state[1][0][0] == j and state[1][0][1] == i):\n","                    if (state[1][1][0] == j and state[1][1][1] == i):\n","                        if (agent_num == AGENT_1):\n","                            output.append('\\033[44m' + '1' + '\\033[0m')\n","                            output.append(' ')\n","                            output.append('\\033[42m' + '2' + '\\033[0m')\n","                        else:\n","                            output.append('\\033[42m' + '2' + '\\033[0m')\n","                            output.append(' ')\n","                            output.append('\\033[44m' + '1' + '\\033[0m')\n","                    else:\n","                        if (agent_num == AGENT_1):\n","                            output.append('\\033[42m' + ' 1 ' + '\\033[0m')\n","                        else:\n","                            output.append('\\033[44m' + ' 1 ' + '\\033[0m')\n","                # p2 의 위치는 파란색으로 표기\n","                elif (state[1][1][0] == j and state[1][1][1] == i):\n","                    if (agent_num == AGENT_1):\n","                        output.append('\\033[44m' + ' 2 ' + '\\033[0m')\n","                    else:\n","                        output.append('\\033[42m' + ' 2 ' + '\\033[0m')\n","                else:\n","                    output.append('\\033[47m' + '   ' + '\\033[0m')\n","\n","                # 새로 wall 을 배치하는 파트\n","                if j >= self.wall_map_width:\n","                    continue\n","                if i < self.wall_map_width:\n","                    if (state[0][1][j][i]):\n","                        output.append(\"|\")\n","                        continue\n","                if i != 0 and i <= self.wall_map_width:\n","                    if (state[0][1][j][i - 1]):\n","                        output.append(\"|\")\n","                        continue\n","                output.append(\" \")\n","            output.append(\"\\n\")\n","\n","        # 첫번째 가이드라인 줄 출력\n","        output.append(\"  \")\n","        for i in range(self.width):\n","            output.append(\" \")\n","            output.append(str(i))\n","            output.append(\"  \")\n","        output.append(\"\\n\")\n","        output.append(\"=========SOUTH=========\")\n","        print(''.join(output))\n","\n","    def step(self, agent_num, action):\n","        if (agent_num != AGENT_1 and agent_num != AGENT_2):\n","            raise Exception(\n","                'QuoridorEnv- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","        self.last_played = agent_num\n","        state = None\n","        width = self.width\n","        if (agent_num != AGENT_1):\n","            state = self.get_flipped_state()\n","        else:\n","            state = (self.map, self.player_status)\n","        # move action\n","        if (action < 4):\n","            if (action == ACT_MOVE_NORTH):\n","                state[1][0][1] += 1\n","            if (action == ACT_MOVE_WEST):\n","                state[1][0][0] -= 1\n","            if (action == ACT_MOVE_SOUTH):\n","                state[1][0][1] -= 1\n","            if (action == ACT_MOVE_EAST):\n","                state[1][0][0] += 1\n","        # 벽 배치하는 action\n","        elif (action < self.all_action.size):\n","            if agent_num == AGENT_1:\n","                state[1][0][2] -= 1\n","            action -= ACT_MOVE_CNT\n","            state[0][action // ((width - 1) * (width - 1))][(action % ((width - 1)\n","                                                                       * (width - 1))) % (width - 1)][(action % ((width - 1) * (width - 1))) // (width - 1)] = True\n","\n","        if (agent_num != AGENT_1):\n","            self.map, self.player_status = self.get_flipped_state(state)\n","        else:\n","            self.map, self.player_status = state\n","        step_reward = self.get_value(agent_num)\n","        step_done = self.ask_end_state((self.map, self.player_status))\n","        self.state_changed = True\n","        return state, step_reward, step_done\n","\n","    def step_move(self, agent_num, action):\n","        if (agent_num != AGENT_1 and agent_num != AGENT_2):\n","            raise Exception(\n","                'QuoridorEnv- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","        if (agent_num != AGENT_1):\n","            state = self.get_flipped_state()\n","        else:\n","            state = (self.map, self.player_status)\n","\n","    def get_state(self, agent_num):\n","        if (agent_num != AGENT_1 and agent_num != AGENT_2):\n","            raise Exception(\n","                'QuoridorEnv- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","        if (agent_num != AGENT_1):\n","            return self.get_flipped_state()\n","        else:\n","            return (self.map, self.player_status)\n","\n","    def get_flipped_state(self, state=\"\"):\n","        if state == \"\":\n","            flipped_map = np.flip(self.map.copy(), (1, 2))\n","            flipped_p_status = np.flip(self.player_status.copy(), 0)\n","            flipped_p_status[0][0] = self.width - 1 - flipped_p_status[0][0]\n","            flipped_p_status[0][1] = self.width - 1 - flipped_p_status[0][1]\n","            flipped_p_status[1][0] = self.width - 1 - flipped_p_status[1][0]\n","            flipped_p_status[1][1] = self.width - 1 - flipped_p_status[1][1]\n","        else:\n","            flipped_map = np.flip(state[0].copy(), (1, 2))\n","            flipped_p_status = np.flip(state[1].copy(), 0)\n","            flipped_p_status[0][0] = self.width - 1 - flipped_p_status[0][0]\n","            flipped_p_status[0][1] = self.width - 1 - flipped_p_status[0][1]\n","            flipped_p_status[1][0] = self.width - 1 - flipped_p_status[1][0]\n","            flipped_p_status[1][1] = self.width - 1 - flipped_p_status[1][1]\n","\n","        return (flipped_map, flipped_p_status)\n","\n","    # state 를 보고 목적지까지 얼마나 멀리 떨어졌는지 판단\n","    def ask_how_far(self, state):\n","        width = self.width\n","        end_line = width - 1\n","        # 이미 종료상태에 도달\n","        if (state[1][0][1] == end_line):\n","            return 0\n","        reached_map = np.array([[False] * width for _ in range(width)])\n","        distance = -1\n","        stack = []\n","        reached_map[state[1][0][0]][state[1][0][1]] = True\n","        stack.append((state[1][0][0], state[1][0][1]))\n","        while len(stack) != 0:\n","            next_stack = []\n","            distance += 1\n","            for pos in stack:\n","                # N\n","                if (pos[1] < width - 1):\n","                    if (not reached_map[pos[0]][pos[1] + 1]):\n","                        if (not ((pos[0] != 0 and state[0][0][pos[0] - 1][pos[1]]) or (pos[0] < width - 1 and state[0][0][pos[0]][pos[1]]))):\n","                            reached_map[pos[0]][pos[1] + 1] = True\n","                            next_stack.append((pos[0], pos[1] + 1))\n","                # W\n","                if (pos[0] != 0):\n","                    if (not reached_map[pos[0] - 1][pos[1]]):\n","                        if (not ((pos[1] != 0 and state[0][1][pos[0] - 1][pos[1] - 1]) or (pos[1] < width - 1 and state[0][1][pos[0] - 1][pos[1]]))):\n","                            reached_map[pos[0] - 1][pos[1]] = True\n","                            next_stack.append((pos[0] - 1, pos[1]))\n","                # S\n","                if (pos[1] != 0):\n","                    if (not reached_map[pos[0]][pos[1] - 1]):\n","                        if (not ((pos[0] != 0 and state[0][0][pos[0] - 1][pos[1] - 1]) or (pos[0] < width - 1 and state[0][0][pos[0]][pos[1] - 1]))):\n","                            reached_map[pos[0]][pos[1] - 1] = True\n","                            next_stack.append((pos[0], pos[1] - 1))\n","                # E\n","                if (pos[0] < width - 1):\n","                    if (not reached_map[pos[0] + 1][pos[1]]):\n","                        if (not ((pos[1] != 0 and state[0][1][pos[0]][pos[1] - 1]) or (pos[1] < width - 1 and state[0][1][pos[0]][pos[1]]))):\n","                            reached_map[pos[0] + 1][pos[1]] = True\n","                            next_stack.append((pos[0] + 1, pos[1]))\n","            # 종료상태에 도달한 것이 있는지 검사\n","            for i in next_stack:\n","                if (i[1] == end_line):\n","                    return distance+1\n","            stack = next_stack\n","        # 종료 상태에 도달할 수 없는 경우\n","        return (-1)\n","\n","    def ask_how_far_opp(self, state):\n","        width = self.width\n","        end_line = 0\n","        # 이미 종료상태에 도달\n","        if (state[1][1][1] == end_line):\n","            return 0\n","        reached_map = np.array([[False] * width for _ in range(width)])\n","        distance = -1\n","        stack = []\n","        reached_map[state[1][1][0]][state[1][1][1]] = True\n","        stack.append((state[1][1][0], state[1][1][1]))\n","        while len(stack) != 0:\n","            next_stack = []\n","            distance += 1\n","            for pos in stack:\n","                # N\n","                if (pos[1] < width - 1):\n","                    if (not reached_map[pos[0]][pos[1] + 1]):\n","                        if (not ((pos[0] != 0 and pos[1] < width - 1 and state[0][0][pos[0] - 1][pos[1]]) or (pos[0] < width - 1 and state[0][0][pos[0]][pos[1]]))):\n","                            reached_map[pos[0]][pos[1] + 1] = True\n","                            next_stack.append((pos[0], pos[1] + 1))\n","                # W\n","                if (pos[0] != 0):\n","                    if (not reached_map[pos[0] - 1][pos[1]]):\n","                        if (not ((pos[1] != 0 and state[0][1][pos[0] - 1][pos[1] - 1]) or (pos[1] < width - 1 and state[0][1][pos[0] - 1][pos[1]]))):\n","                            reached_map[pos[0] - 1][pos[1]] = True\n","                            next_stack.append((pos[0] - 1, pos[1]))\n","                # S\n","                if (pos[1] != 0):\n","                    if (not reached_map[pos[0]][pos[1] - 1]):\n","                        if (not ((pos[0] != 0 and state[0][0][pos[0] - 1][pos[1] - 1]) or (pos[0] < width - 1 and state[0][0][pos[0]][pos[1] - 1]))):\n","                            reached_map[pos[0]][pos[1] - 1] = True\n","                            next_stack.append((pos[0], pos[1] - 1))\n","                # E\n","                if (pos[0] < (width - 1)):\n","                    if (not reached_map[pos[0] + 1][pos[1]]):\n","                        if (not ((pos[1] != 0 and state[0][1][pos[0]][pos[1] - 1]) or (pos[1] < width - 1 and state[0][1][pos[0]][pos[1]]))):\n","                            reached_map[pos[0] + 1][pos[1]] = True\n","                            next_stack.append((pos[0] + 1, pos[1]))\n","            # 종료상태에 도달한 것이 있는지 검사\n","            for i in next_stack:\n","                if (i[1] == end_line):\n","                    return distance+1\n","            stack = next_stack\n","        # 종료 상태에 도달할 수 없는 경우\n","        return (-1)\n","\n","    # get_value\n","    def get_value(self, agent_num):\n","        if (agent_num != AGENT_1 and agent_num != AGENT_2):\n","            raise Exception(\n","                'QuoridorEnv- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","        # 1.가장 간단한 value_function\n","        # 승리시 150\n","        # 패배시 -150\n","        # 그외 -1\n","        isItEnd = self.ask_end_state((self.map, self.player_status))\n","        if (self.value_mode == 0):\n","            if (isItEnd == 0):\n","                if (self.ask_opponent_will_win(agent_num)):\n","                    return -150\n","                else:\n","                    return -1\n","            elif (isItEnd == agent_num):\n","                return 150\n","            else:\n","                return -150\n","\n","        # 2.약간 복잡한 value_function\n","        # 승리시 100\n","        # 패배시 -100\n","        # 그외 y축 값에 따라 차등지급\n","        # 산식: reward = ($도착 라인과 거리 (벽무시)) * -1\n","        # ex) 5 x 5 게임판에서 (1, 2): -2, (3, 4): 200, (4, 3): -1\n","        if (self.value_mode == 1):\n","            if (isItEnd == 0):\n","                if (self.ask_opponent_will_win(agent_num)):  # 상대방의 승리 직전\n","                    return -100\n","                elif (agent_num == AGENT_1):  # 일반적인 state\n","                    return 1 + self.player_status[0][1] - self.width\n","                else:\n","                    return -self.player_status[1][1]\n","            elif (isItEnd == agent_num):  # 나의 승리\n","                return 100\n","            else:  # 상대방의 승리\n","                return -100\n","\n","        # 3.조금 더 복잡한 value_function\n","        # 주의점: nq learning 할때 깊이를 충분히 깊게 탐색해야할 것. (아예 end state까지 탐색을 권장)\n","        #           이 value_function을 도입한 에이전트는 티배깅(인성질)을 할 가능성이 있음...\n","        # 승리시 1000\n","        # 패배시 -1000\n","        # 그 외 \"상대와 나의\" y축 값에 따라 차등지급\n","        # 산식 reward = (상대의 end_line 과의 거리 (벽무시)) - (나의 end_line 과의 거리 (벽무시)) * 2 - 1\n","        if (self.value_mode == 2):\n","            if (isItEnd == 0):\n","                if (self.ask_opponent_will_win(agent_num)):  # 상대방의 승리 직전\n","                    return -1000\n","                if (agent_num == AGENT_1):\n","                    return self.player_status[1][1] - (self.width - 1 - self.player_status[0][1]) * 2 - 1\n","                else:\n","                    return self.width - 1 - self.player_status[0][1] - self.player_status[1][1] * 2 - 1\n","            elif (isItEnd == agent_num):\n","                return 1000\n","            else:\n","                return -1000\n","\n","        # 4. 많이 복잡한 value_function\n","        # 주의점: 연산량이 상당하기에 탐색 범위가 넓으면 학습에 상당한 시간이 걸릴 것임.\n","        # 장점: 직관적으로 고개가 끄덕여지는 reward 를 반환.\n","        # 승리시 1000\n","        # 패배시 -1000\n","        # 그 외  {승리 조건까지 도달하기에 얼마나 남았는지 벽을 포함하여 연산한 값} * -1\n","        if (self.value_mode == 3):\n","            if (isItEnd == 0):\n","                if (self.ask_opponent_will_win(agent_num)):  # 상대방의 승리 직전\n","                    return -1000\n","                if (agent_num == AGENT_1):\n","                    return -self.ask_how_far((self.map, self.player_status))\n","                else:\n","                    return -self.ask_how_far_opp((self.map, self.player_status))\n","            elif (isItEnd == agent_num):\n","                return 1000\n","            else:\n","                return -1000\n","\n","        # 5. 아주 많이 복잡한 value_function\n","        # 주의점: 연산량이 상당하기에 탐색 범위가 넓으면 학습에 상당한 시간이 걸릴 것임.\n","        # 장점: 직관적으로 고개가 끄덕여지는 reward 를 반환.\n","        # 승리시 1000\n","        # 패배시 -1000\n","        # 그 외 {상대의 도착까지 남은 수} - {승리 조건까지 도달하기에 얼마나 남았는지 벽을 포함하여 연산한 값} * 2 -1\n","        if (self.value_mode == 4):\n","            if (isItEnd == 0):\n","                if (self.ask_opponent_will_win(agent_num)):  # 상대방의 승리 직전\n","                    return -1000\n","                if (agent_num == AGENT_1):\n","                    return self.ask_how_far_opp((self.map, self.player_status)) - self.ask_how_far((self.map, self.player_status)) * 2 - 1\n","                else:\n","                    return self.ask_how_far((self.map, self.player_status)) - self.ask_how_far_opp((self.map, self.player_status)) * 2 - 1\n","            elif (isItEnd == agent_num):\n","                return 1000\n","            else:\n","                return -1000\n","\n","    # 종료상태 여부를 확인하는 메서드\n","    # 1: 입력된 state상에 state[1][0][]의 주인이 승리\n","    # 2: 입력된 state상에 state[1][1][]의 주인이 승리\n","\n","    def ask_end_state(self, state):\n","        if (state[1][0][1] == self.width-1):\n","            return AGENT_1\n","        elif (state[1][1][1] == 0):\n","            return AGENT_2\n","        else:\n","            return 0\n","\n","    def ask_opponent_will_win(self, agent_num):\n","        width = self.width\n","        if (agent_num == AGENT_1):  # p2의 승리임박을 확인\n","            if (self.player_status[1][1] == 1):\n","                if ((self.player_status[1][0] != 0 and self.map[0][self.player_status[1][0] - 1][0]) or (self.player_status[1][0] < width - 1 and self.map[0][self.player_status[1][0]][0])):\n","                    return False\n","                else:\n","                    return True\n","            else:\n","                return False\n","        elif (agent_num == AGENT_2):  # p1의 승리임박을 확인\n","            if (self.player_status[0][1] == width-2):\n","                if ((self.player_status[0][0] != 0 and self.map[0][self.player_status[0][0] - 1][width-2]) or (self.player_status[0][0] < width - 1 and self.map[0][self.player_status[0][0]][width-2])):\n","                    return False\n","                else:\n","                    return True\n","            else:\n","                return False\n","        else:\n","            raise Exception(\n","                'QuoridorEnv.ask_opponent_will_win()- agent_num 에러!\\n잘못된 agent_num을 입력하였음!')\n","\n","    def ask_state_changed(self):\n","        return self.state_changed\n","\n","    def set_state_changed_false(self):\n","        self.state_changed = False\n","\n","\n","# q = QuoridorEnv(width=5, value_mode=1)\n","# agent_1 = q.register_agent()\n","# agent_2 = q.register_agent()\n","# print(q.step(agent_1, 0))  # agent_1 이 action 10을 수행\n","# print(q.get_legal_action(q.get_state(agent_1)))\n","# q.step(agent_2, 0)\n","# q.step(agent_1, 11)\n","# q.step(agent_1, 16)\n","# q.step(agent_1, 19)\n","# q.render(agent_1)\n","# print(q.ask_how_far_opp(q.get_state(agent_1)))\n","# print(q.ask_how_far(q.get_state(agent_1)))\n","# print(q.get_legal_action(q.get_state(agent_1)))\n","# g = QuoridorGUI(q)\n","# g.startGame()\n"],"metadata":{"id":"ROD9lTxRrn2F","executionInfo":{"status":"ok","timestamp":1670653277369,"user_tz":-540,"elapsed":690,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWjbtv73rItg","executionInfo":{"status":"ok","timestamp":1670653294210,"user_tz":-540,"elapsed":4655,"user":{"displayName":"Point Check","userId":"12583793856941705124"}},"outputId":"7df9f478-2e4c-4ae2-cd55-9fe6731f2d84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Use Device:  cuda\n"]}],"source":["import collections\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Use Device: \", DEVICE)\n","\n","learning_rate = 0.0005\n","gamma = 1\n","buffer_limit = 100000\n","batch_size = 128\n","\n","WIDTH = 5"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Z7Bpt4hQrIth","executionInfo":{"status":"ok","timestamp":1670653296375,"user_tz":-540,"elapsed":2,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"outputs":[],"source":["class ReplayBuffer():\n","    def __init__(self):\n","        self.buffer = collections.deque(maxlen=buffer_limit)\n","\n","    def put(self, transition):\n","        self.buffer.append(transition)\n","\n","    def sample(self, n):\n","        mini_batch = random.sample(self.buffer, n)\n","        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n","\n","        for transition in mini_batch:\n","            s, a, r, s_prime, done_mask = transition\n","            s_lst.append(s)\n","            a_lst.append([a])\n","            r_lst.append([r])\n","            s_prime_lst.append(s_prime)\n","            done_mask_lst.append([done_mask])\n","\n","        return torch.tensor(s_lst, dtype=torch.float).to(DEVICE), torch.tensor(a_lst).to(DEVICE), \\\n","            torch.tensor(r_lst).to(DEVICE), torch.tensor(s_prime_lst, dtype=torch.float).to(DEVICE), \\\n","            torch.tensor(done_mask_lst).to(DEVICE)\n","\n","    def size(self):\n","        return len(self.buffer)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5ujkF67KrIth","executionInfo":{"status":"ok","timestamp":1670653298239,"user_tz":-540,"elapsed":1,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"outputs":[],"source":["class Qnet(nn.Module):\n","    def __init__(self):\n","        super(Qnet, self).__init__()\n","        self.fc1 = nn.Linear(6 + ((WIDTH-1)*(WIDTH-1)*2), 256)\n","        self.fc2 = nn.Linear(256, 256)\n","        self.fc3 = nn.Linear(256, 256)\n","        self.fc4 = nn.Linear(256, 256)\n","        self.fc5 = nn.Linear(256, 4 + ((WIDTH-1)*(WIDTH-1)*2))\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = F.relu(self.fc4(x))\n","        x = self.fc5(x)\n","        return x\n","\n","    def sample_action(self, obs, epsilon, available_actions):\n","        out = self.forward(obs)\n","        coin = random.random()\n","        if coin < epsilon:\n","            return random.choice(available_actions)\n","        else:\n","            action = out.argmax().item()\n","            if action in available_actions:\n","                return action\n","            else:\n","                # out_list = out.tolist()\n","                # new_out_list = []\n","                # for i in range(len(out_list)):\n","                #     if i not in available_actions:\n","                #         new_out_list.append(-100)\n","                #     else:\n","                #         new_out_list.append(out_list[i])\n","                # return new_out_list.index(max(new_out_list))\n","                return random.choice(available_actions)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lHd0d-JYrIti","executionInfo":{"status":"ok","timestamp":1670653300078,"user_tz":-540,"elapsed":1,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"outputs":[],"source":["def train(q, q_target, memory, optimizer):\n","    for i in range(10):\n","        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n","\n","        q_out = q(s)\n","        q_a = q_out.gather(1, a)\n","        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n","        target = r + gamma * max_q_prime * done_mask\n","        loss = F.smooth_l1_loss(q_a, target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8xvYj2W5rIti","executionInfo":{"status":"ok","timestamp":1670653300614,"user_tz":-540,"elapsed":2,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"outputs":[],"source":["def getLinearState(state):\n","    map_state, player_status = state\n","\n","    ret_list = []\n","\n","    ret_list.append(player_status[0][0])\n","    ret_list.append(player_status[0][1])\n","    ret_list.append(player_status[0][2])\n","    ret_list.append(player_status[1][0])\n","    ret_list.append(player_status[1][1])\n","    ret_list.append(player_status[1][2])\n","\n","    for i in map_state:\n","        for j in i:\n","            for k in j:\n","                ret_list.append(k)\n","    return ret_list"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Tw6kfDbzrIti","executionInfo":{"status":"ok","timestamp":1670653525047,"user_tz":-540,"elapsed":992,"user":{"displayName":"Point Check","userId":"12583793856941705124"}}},"outputs":[],"source":["def main():\n","    env = QuoridorEnv(width=WIDTH, value_mode=0)\n","    q = Qnet().to(DEVICE)\n","    q_target = Qnet().to(DEVICE)\n","    q_target.load_state_dict(q.state_dict())\n","    memory = ReplayBuffer()\n","\n","    print_interval = 100\n","    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n","\n","    for n_epi in range(20_0000):\n","        epsilon = max(0.01, 0.08 - 0.01 * (n_epi / 200))\n","        env.reset()\n","        done = False\n","\n","        while not done:\n","            agent_turn = 300 - env.last_played\n","\n","            # os.system('cls')\n","            # env.render(agent_turn)\n","            original_state = env.get_state(agent_turn)\n","            state = getLinearState(original_state)\n","\n","            available_actions = env.get_legal_action(original_state)\n","            action = q.sample_action(torch.tensor(\n","                state).float().to(DEVICE), epsilon, available_actions)\n","\n","            # print(available_actions)\n","            # print(\"state: \", state)\n","            # print(\"action: \", action)\n","            state_prime, reward, done = env.step(agent_turn, action)\n","            state_prime = getLinearState(state_prime)\n","\n","            done_mask = 0.0 if done else 1.0\n","            memory.put((state, action, reward, state_prime, done_mask))\n","\n","            if done:\n","                break\n","\n","        if memory.size() > 2000:\n","            train(q, q_target, memory, optimizer)\n","\n","        if n_epi % print_interval == 0 and n_epi != 0:\n","            q_target.load_state_dict(q.state_dict())\n","            print(\"# of episode :{}, avg score : {:.1f}\".format(\n","                n_epi, reward))\n","            torch.save(q.state_dict(),\n","                       f'/gdrive/MyDrive/ossp2/DQN/Quoridor_DQN_w{WIDTH}_{n_epi}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAlcgiaCrItj","outputId":"963b66aa-76c2-4ae1-be67-bc226269de7d"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-1fce9d25ad1b>:25: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n","  action = q.sample_action(torch.tensor(\n"]},{"output_type":"stream","name":"stdout","text":["# of episode :100, avg score : 150.0\n","# of episode :200, avg score : 150.0\n","# of episode :300, avg score : 150.0\n","# of episode :400, avg score : 150.0\n","# of episode :500, avg score : 150.0\n","# of episode :600, avg score : 150.0\n","# of episode :700, avg score : 150.0\n"]}],"source":["main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"b7377f19eab4b8c2e19b4d5b732c435591579d0f123dd21b146d33dfd161e508"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}